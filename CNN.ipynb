{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maram-Elsayed/Panelty-Function-With-Gradient-Descent/blob/master/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clUhIhqr3g0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4_Id5GI4CWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caSo0BNT4Fp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import PIL\n",
        "import cv2\n",
        "import keras\n",
        "from PIL import Image\n",
        "import os, os.path\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from scipy import ndimage, misc\n",
        "from keras.utils import to_categorical\n",
        " \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRg8EGuV4H7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imageDir_train = [\"drive/Colab/daisy_0/\",\"drive/Colab/dandelion_1/\",\"drive/Colab/rose_2/\",\"drive/Colab/sunflower_3/\",\"drive/Colab/tulip_4/\"]\n",
        "\n",
        "y=0\n",
        "train_x=[]\n",
        "flowers=np.array([['Pixels','Target']])\n",
        "train_y=np.array([])\n",
        "valid_image_extensions = [\".jpg\", \".jpeg\", \".png\"]\n",
        "valid_image_extensions = [item.lower() for item in valid_image_extensions]\n",
        "for f in range(len(imageDir_train)):\n",
        " image_path_list_train=[]\n",
        " for file in os.listdir(imageDir_train[f]):    \n",
        "    extension = os.path.splitext(file)[1]\n",
        "    if extension.lower() not in valid_image_extensions:\n",
        "        continue\n",
        "    image_path_list_train.append(os.path.join(imageDir_train[f], file))\n",
        "\n",
        "\n",
        "\n",
        " for imagePath in image_path_list_train:\n",
        "   i= np.array(Image.open(imagePath))\n",
        "   res = cv2.resize(i, dsize=(320, 230), interpolation=cv2.INTER_CUBIC)\n",
        "   iar=np.asarray(res)\n",
        "   flowers=np.append(flowers,[[iar,imageDir_train[f][-2:-1]]] ,0)\n",
        "   y+=1\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9sEdyHl4PZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flowers = np.delete(flowers, (0), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MUTRizR4TLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.shuffle(flowers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z5wuMe-4U_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x in range(len(flowers)):\n",
        " train_y=np.append(train_y,[flowers[x][1]])\n",
        "for x in range(len(flowers)):\n",
        " train_x.append(flowers[x][0])\n",
        "train_x=np.array(train_x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kho0BBb4VUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = train_x.reshape(-1, 320,230, 3)\n",
        "train_x = train_x.astype('float32')\n",
        "train_x /= 255\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrH3l3eX4cLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y= to_categorical(train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPDRSmeQ4cOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_x=train_x[-300:]\n",
        "train_x=train_x[:-300]\n",
        "valid_y=train_y[-300:]\n",
        "train_y=train_y[:-300]\n",
        "\n",
        "\n",
        "test_x=train_x[-300:]\n",
        "train_x=train_x[:-300]\n",
        "test_y=train_y[-300:]\n",
        "train_y=train_y[:-300]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYEKtVCY4cQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "\n",
        "fashion_model = Sequential()\n",
        "fashion_model.add(Convolution2D(64, kernel_size=(5, 5),activation='linear',input_shape=(320,230,3),padding='same'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.01))\n",
        "fashion_model.add(MaxPooling2D((2, 2),padding='same'))\n",
        "fashion_model.add(Convolution2D(64, (5, 5), activation='linear',padding='same'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.01))\n",
        "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "fashion_model.add(Convolution2D(128, (5, 5), activation='linear',padding='same'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.01))                  \n",
        "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "fashion_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
        "fashion_model.add(Convolution2D(516, (5, 5), activation='linear',padding='same'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.01))                  \n",
        "fashion_model.add(Flatten())\n",
        "fashion_model.add(Dense(128, activation='linear'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.001))  \n",
        "fashion_model.add(Dense(128, activation='linear'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.001))  \n",
        "fashion_model.add(Dense(128, activation='linear'))\n",
        "fashion_model.add(LeakyReLU(alpha=0.001))  \n",
        "fashion_model.add(Dense(5, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbLEkQnF4ccm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy6NRljt4wHM",
        "colab_type": "code",
        "outputId": "7bfe00fa-337c-4338-e6db-7c07ec264689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "\n",
        "\n",
        "callbacks = [\n",
        "   keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0,\n",
        "                              patience=3,\n",
        "                              verbose=1, mode='auto')\n",
        "]\n",
        "fashion_train = fashion_model.fit(train_x, train_y, batch_size=64,epochs=30,verbose=1,validation_data=(valid_x, valid_y),callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2410 samples, validate on 300 samples\n",
            "Epoch 1/30\n",
            "2410/2410 [==============================] - 34s 14ms/step - loss: 1.5888 - acc: 0.2398 - val_loss: 1.4725 - val_acc: 0.2867\n",
            "Epoch 2/30\n",
            "2410/2410 [==============================] - 33s 14ms/step - loss: 1.3879 - acc: 0.3934 - val_loss: 1.3321 - val_acc: 0.4100\n",
            "Epoch 3/30\n",
            "2410/2410 [==============================] - 33s 14ms/step - loss: 1.2265 - acc: 0.4739 - val_loss: 1.1901 - val_acc: 0.4933\n",
            "Epoch 4/30\n",
            "2410/2410 [==============================] - 33s 14ms/step - loss: 1.1466 - acc: 0.5253 - val_loss: 1.1047 - val_acc: 0.5367\n",
            "Epoch 5/30\n",
            "2410/2410 [==============================] - 33s 14ms/step - loss: 1.0986 - acc: 0.5606 - val_loss: 1.0348 - val_acc: 0.5800\n",
            "Epoch 6/30\n",
            "2410/2410 [==============================] - 33s 14ms/step - loss: 1.0447 - acc: 0.5913 - val_loss: 1.0032 - val_acc: 0.6167\n",
            "Epoch 7/30\n",
            "2410/2410 [==============================] - 33s 14ms/step - loss: 0.9913 - acc: 0.5988 - val_loss: 1.0587 - val_acc: 0.5433\n",
            "Epoch 8/30\n",
            "2410/2410 [==============================] - 33s 14ms/step - loss: 0.9595 - acc: 0.6212 - val_loss: 0.9418 - val_acc: 0.6167\n",
            "Epoch 9/30\n",
            "2410/2410 [==============================] - 33s 14ms/step - loss: 0.9393 - acc: 0.6324 - val_loss: 0.8830 - val_acc: 0.6433\n",
            "Epoch 10/30\n",
            "2410/2410 [==============================] - 33s 14ms/step - loss: 0.8843 - acc: 0.6481 - val_loss: 0.9168 - val_acc: 0.6200\n",
            "Epoch 11/30\n",
            "2410/2410 [==============================] - 33s 14ms/step - loss: 0.8447 - acc: 0.6610 - val_loss: 0.9098 - val_acc: 0.6033\n",
            "Epoch 12/30\n",
            "2410/2410 [==============================] - 33s 14ms/step - loss: 0.8177 - acc: 0.6763 - val_loss: 0.9072 - val_acc: 0.6533\n",
            "Epoch 00012: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wngiUEzv422r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_eval = fashion_model.evaluate(test_x, test_y, verbose=0)\n",
        "\n",
        "print('Test accuracy:', test_eval[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}